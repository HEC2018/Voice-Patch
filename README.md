# Voice-Patch
(From Abstract part of paper) Many schools, companies and organizations have opted to use online conference tools such as Zoom and Skype due to the serious COVID-19 pandemic. However, due to the unstable connections, many users are frustrated by the quality of online meetings, especially when some fragments are missed in the audio. We aim to create a tool that first transcribes the audio, then identifies the missing fragments (if any), and finally fills in the fragment based on the surrounding context.  For this paper, we have created a tool named Voice Patch that uses DeepSpeech to transcribe the audio and uses RNN models to complete the fragment based on the assumption that the audio is one sentence and the missing fragment is exactly one word. We were able to achieve a training accuracy of 16.954% and validation accuracy of 36.25%. We believe that this tool can be really helpful in improving the user experience in using online meeting tools in the future. 
